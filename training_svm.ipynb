{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415fd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as sk\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.decomposition as decomp\n",
    "import sklearn.preprocessing as preproc\n",
    "import sklearn.pipeline as skp\n",
    "import sklearn.model_selection as skmodel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "699483c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train, test, cross_validate=None, k=10, dim_reduc=None, norms=True, kernel=\"LinearSVC\", final_pred=False, get_coefs=False):\n",
    "    \"\"\"\n",
    "    Function to train svm\n",
    "    :param train: train data... (in panda dataframe)\n",
    "    :param test: test data (itou)\n",
    "    :param cross_validate: whether or not to perform cross validation (possible values: leave-one-out and k-fold)\n",
    "    :param k: k parameter for k-fold cross validation\n",
    "    :param dim_reduc: dimensionality reduction of input data. Implemented values are pca and som.\n",
    "    :param norms: perform normalisations, i.e. z-scores and L2 (default True)\n",
    "    :param kernel: kernel for SVM\n",
    "    :param final_pred: do the final predictions?\n",
    "    :param get_coefs, if true, writes to disk (coefficients.csv) and plots the most important coefficients for each class\n",
    "    :return: returns a pipeline with a fitted svm model, and if possible prints evaluation and writes to disk:\n",
    "    confusion_matrix.csv, misattributions.csv and (if required) FINAL_PREDICTIONS.csv\n",
    "    \"\"\"\n",
    "\n",
    "    print(\".......... Formatting data ........\")\n",
    "    # Save the classes\n",
    "    classes = list(train.loc[:, 'author'])\n",
    "    train = train.drop(['author', 'lang'], axis=1)\n",
    "    train=train.drop(train.columns[0], axis=1)\n",
    "    train[\"index\"]=range(1,len(train)+1)\n",
    "\n",
    "    if test is not None:\n",
    "        classes_test = list(test.loc[:, 'author'])\n",
    "        preds_index = list(df_test.iloc[:,0])\n",
    "        test = test.drop(['author', 'lang'], axis=1)\n",
    "        test=test.drop(test.columns[0], axis=1)\n",
    "        test[\"index\"]=range(1,len(test)+1)\n",
    "\n",
    "    nfeats = train.columns.__len__()\n",
    "\n",
    "    # CREATING PIPELINE\n",
    "    print(\".......... Creating pipeline according to user choices ........\")\n",
    "    estimators = []\n",
    "\n",
    "    if norms:\n",
    "        # Z-scores\n",
    "        # TODO: me suis embeté à implémenter quelque chose qui existe\n",
    "        # déjà via sklearn.preprocessing.StandardScaler()\n",
    "        print(\".......... using normalisations ........\")\n",
    "        estimators.append(('scaler', preproc.StandardScaler()))\n",
    "        # NB: j'utilise le built-in\n",
    "        # normalisation L2\n",
    "        # cf. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer\n",
    "\n",
    "        estimators.append(('normalizer', preproc.Normalizer()))\n",
    "\n",
    "    print(\".......... choosing SVM ........\")\n",
    "\n",
    "    if kernel == \"LinearSVC\":\n",
    "        # try a faster one\n",
    "        estimators.append(('model', sk.LinearSVC()))\n",
    "        # classif = sk.LinearSVC()\n",
    "\n",
    "    else:\n",
    "        estimators.append(('model', sk.SVC(kernel=kernel, probability=True)))\n",
    "        # classif = sk.SVC(kernel=kernel)\n",
    "\n",
    "    print(\".......... Creating pipeline with steps ........\")\n",
    "    print(estimators)\n",
    "    pipe = skp.Pipeline(estimators)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cross_validate is not None:\n",
    "        if cross_validate == 'leave-one-out':\n",
    "            myCV = skmodel.LeaveOneOut()\n",
    "\n",
    "        if cross_validate == 'k-fold':\n",
    "            myCV = skmodel.KFold(n_splits=k)\n",
    "\n",
    "        print(\".......... \"+ cross_validate +\" cross validation will be performed ........\")\n",
    "        print(\".......... using \" + str(myCV.get_n_splits(train)) + \" samples ........\")\n",
    "\n",
    "        # Will need to\n",
    "        # 1. train a model\n",
    "        # 2. get prediction\n",
    "        # 3. compute score: precision, recall, F1 for all categories\n",
    "\n",
    "        preds = skmodel.cross_val_predict(pipe, train, classes, cv=myCV, verbose=1, n_jobs=-1)\n",
    "        cv_results = skmodel.cross_validate(pipe, train, classes, cv=myCV, verbose=1, n_jobs=-1)\n",
    "\n",
    "        # and now, leave one out evaluation (very small redundancy here, one line that could be stored elsewhere)\n",
    "        unique_labels = list(set(classes))\n",
    "        pd.DataFrame(metrics.confusion_matrix(classes, preds, labels=unique_labels),\n",
    "                         index=['true:{:}'.format(x) for x in unique_labels],\n",
    "                         columns=['pred:{:}'.format(x) for x in unique_labels]).to_csv(\"confusion_matrix.csv\")\n",
    "\n",
    "        print(metrics.classification_report(classes, preds))\n",
    "        # writing misattributions\n",
    "        pd.DataFrame([i for i in zip(list(train.index), list(classes), list(preds)) if i[1] != i[2] ],\n",
    "                         columns=[\"id\", \"True\", \"Pred\"]\n",
    "                         ).set_index('id').to_csv(\"misattributions.csv\")\n",
    "\n",
    "        # and now making the model for final preds after leave one out if necessary\n",
    "        if final_pred or get_coefs:\n",
    "            print(\".......... Training final SVM with all train set ........\")\n",
    "            pipe.fit(train, classes)\n",
    "\n",
    "        if final_pred:\n",
    "            preds = pipe.predict_proba(test)\n",
    "    \n",
    "        return pipe, cv_results\n",
    "\n",
    "    \n",
    "    # And now the simple case where there is only one svm to train\n",
    "    else:\n",
    "        pipe.fit(train, classes)\n",
    "        preds = pipe.predict_proba(test)\n",
    "        # and evaluate\n",
    "        unique_labels = list(set(classes + classes_test))\n",
    "\n",
    "        #pd.DataFrame(metrics.confusion_matrix(classes_test, preds, labels=unique_labels),\n",
    "        #                 index=['true:{:}'.format(x) for x in unique_labels],\n",
    "        #                 columns=['pred:{:}'.format(x) for x in unique_labels]).to_csv(\"confusion_matrix.csv\")\n",
    "\n",
    "        #print(metrics.classification_report(classes_test, preds))\n",
    "\n",
    "    # AND NOW, we need to evaluate or create the final predictions\n",
    "    if final_pred:\n",
    "        print(\".......... Writing final predictions to FINAL_PREDICTIONS.csv ........\")\n",
    "        # Get the decision function too\n",
    "        myclasses = pipe.classes_\n",
    "        decs = pipe.decision_function(test)\n",
    "        #######ERROR --- resolu\n",
    "        dists = {}\n",
    "        dists[\"AU(-)/CAE(+)\"] = decs\n",
    "\n",
    "        pd.DataFrame(data={**{'filename': preds_index, 'AU_proba': list(preds), 'CAE_proba' : None, \"AU(-)/CAE(+)\":list(decs)}, **dists}).to_csv(\"FINAL_PREDICTIONS.csv\")\n",
    "\n",
    "    if get_coefs:\n",
    "        # For “one-vs-rest” LinearSVC the attributes coef_ and intercept_ have the shape (n_classes, n_features) and\n",
    "        # (n_classes,) respectively.\n",
    "        # Each row of the coefficients corresponds to one of the n_classes “one-vs-rest” classifiers and similar for the\n",
    "        # intercepts, in the order of the “one” class.\n",
    "        # Save coefficients for the last model\n",
    "        pandas.DataFrame(pipe.named_steps['model'].coef_,\n",
    "                         index=pipe.classes_,\n",
    "                         columns=train.columns).to_csv(\"coefficients.csv\")\n",
    "\n",
    "        # TODO: optionalise  the number of top_features… ?\n",
    "        for i in range(len(pipe.classes_)):\n",
    "            plot_coefficients(pipe.named_steps['model'].coef_[i], train.columns, pipe.classes_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67aaf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"train.csv\")\n",
    "df_test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e9743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... Formatting data ........\n",
      ".......... Creating pipeline according to user choices ........\n",
      ".......... using normalisations ........\n",
      ".......... choosing SVM ........\n",
      ".......... Creating pipeline with steps ........\n",
      "[('scaler', StandardScaler()), ('normalizer', Normalizer()), ('model', LinearSVC())]\n",
      ".......... k-fold cross validation will be performed ........\n",
      ".......... using 10 samples ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AU       0.96      0.96      0.96        46\n",
      "         CAE       0.96      0.96      0.96        55\n",
      "\n",
      "    accuracy                           0.96       101\n",
      "   macro avg       0.96      0.96      0.96       101\n",
      "weighted avg       0.96      0.96      0.96       101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "pipe_text_CV, scores_text_CV= train_svm(df_train, df_test, cross_validate='k-fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1af1fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220805</td>\n",
       "      <td>0.082177</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241964</td>\n",
       "      <td>0.075271</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157832</td>\n",
       "      <td>0.038972</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126612</td>\n",
       "      <td>0.054724</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.141717</td>\n",
       "      <td>0.051384</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.112758</td>\n",
       "      <td>0.038979</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.114959</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.105856</td>\n",
       "      <td>0.040657</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.118132</td>\n",
       "      <td>0.069238</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.224275    0.077451         1.0\n",
       "1  0.220805    0.082177         1.0\n",
       "2  0.241964    0.075271         1.0\n",
       "3  0.157832    0.038972         0.9\n",
       "4  0.126612    0.054724         1.0\n",
       "5  0.141717    0.051384         1.0\n",
       "6  0.112758    0.038979         1.0\n",
       "7  0.114959    0.038072         1.0\n",
       "8  0.105856    0.040657         1.0\n",
       "9  0.118132    0.069238         1.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores_text_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "aa62737b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores_text_CV['test_score'][:3])/len(scores_text_CV['test_score'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d5d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... Formatting data ........\n",
      ".......... Creating pipeline according to user choices ........\n",
      ".......... using normalisations ........\n",
      ".......... choosing SVM ........\n",
      ".......... Creating pipeline with steps ........\n",
      "[('scaler', StandardScaler()), ('normalizer', Normalizer()), ('model', SVC(kernel='linear', probability=True))]\n",
      ".......... Writing final predictions to FINAL_PREDICTIONS.csv ........\n"
     ]
    }
   ],
   "source": [
    "train_svm(df_train, df_test, final_pred=True, kernel=\"linear\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
