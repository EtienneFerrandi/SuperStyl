{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse supervisée\n",
    "\n",
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"All I've Got to Do\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1963</td>\n",
       "      <td>Whenever I want you around yeh  All I gotta do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>\"All Together Now\"</td>\n",
       "      <td>Yellow Submarine</td>\n",
       "      <td>Lennon-McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1967</td>\n",
       "      <td>One two three four Can I have a little more Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>\"All You Need Is Love\"</td>\n",
       "      <td>Magical Mystery Tour</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1967</td>\n",
       "      <td>Love, love, love Love, love, love Love, love, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    Song  \\\n",
       "0           1   \"Across the Universe\"   \n",
       "1           2    \"All I've Got to Do\"   \n",
       "2           3         \"All My Loving\"   \n",
       "3           5      \"All Together Now\"   \n",
       "4           6  \"All You Need Is Love\"   \n",
       "\n",
       "                                    Album Debut     Songwriter(s)  \\\n",
       "0                                     Let It Be            Lennon   \n",
       "1  UK: With the Beatles\\n US: Meet the Beatles!            Lennon   \n",
       "2  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "3                              Yellow Submarine  Lennon-McCartney   \n",
       "4                          Magical Mystery Tour            Lennon   \n",
       "\n",
       "  Lead Vocal(s)  Year                                             Lyrics  \n",
       "0        Lennon  1968  Words are flowing out like endless rain into a...  \n",
       "1        Lennon  1963  Whenever I want you around yeh  All I gotta do...  \n",
       "2     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...  \n",
       "3     McCartney  1967  One two three four Can I have a little more Fi...  \n",
       "4        Lennon  1967  Love, love, love Love, love, love Love, love, ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librairie pandas (manipulation de données csv, dataframe, etc.)\n",
    "import pandas as pd\n",
    "\n",
    "# Import et lecture du corpus :\n",
    "corpus = pd.read_csv('corpus_nettoye.csv')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse supervisée\n",
    "\n",
    "\n",
    "Pour cette partie, nous allons réutiliser du code stocké dans un package, et, pour ce faire, nous couler dans le moule attendu par ce package. Commençons par créer le dossier avec les données nécessaires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the corpus into the expected format for our functions\n",
    "import jagen_will.preproc.tuyau as tuy\n",
    "import jagen_will.preproc.features_extract as fex\n",
    "from jagen_will.preproc.text_count import count_process\n",
    "import os\n",
    "\n",
    "myTexts = []\n",
    "\n",
    "\n",
    "### HACK: j'écris les données dont on a besoin pour l'usage prévu du module\n",
    "# Create folder structure\n",
    "if not os.path.exists('./data/songs_text/train/'):\n",
    "    os.makedirs(\"./data/songs_text/train/\")\n",
    "\n",
    "if not os.path.exists('./data/songs_text/test/'):\n",
    "    os.makedirs(\"./data/songs_text/test/\")\n",
    "    \n",
    "# Start by writing fulltext output\n",
    "for index, row in corpus.iterrows():\n",
    "    if isinstance(row[\"Lyrics\"], str) and row[\"Lyrics\"] is not \"\":\n",
    "        if row[\"Songwriter(s)\"] in ['McCartney', 'Lennon']:\n",
    "            folder = 'train/'\n",
    "        else:\n",
    "            folder = 'test/'\n",
    "        \n",
    "        # Fulltext\n",
    "        with open(\"data/songs_text/\"+folder+row[\"Songwriter(s)\"]+\"_\"+row[\"Song\"].replace('\"', '').replace(' ','-')+'.txt', 'w') as f:\n",
    "            f.write(row[\"Lyrics\"])\n",
    "            \n",
    "        # TODO: write a version with lemma and POS\n",
    "        # Lemmatised\n",
    "        # POS  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now we can try to analyse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 119/119 [00:00<00:00, 280.47it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 279.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the table with data to be analysed\n",
    "# Either run this from command line\n",
    "# python main.py -t chars -n 3 -s data/songs_text/train/* #chars 3-grams\n",
    "# python main.py -t chars -n 3 -f feature_list_chars3grams5000mf.json -s data/songs_text/test/* *# feats common with train\n",
    "# OR \n",
    "# the following bloc of code\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import jagen_will.preproc.tuyau as tuy\n",
    "import jagen_will.preproc.features_extract as fex\n",
    "from jagen_will.preproc.text_count import count_process\n",
    "import fasttext\n",
    "import pandas\n",
    "import json\n",
    "# from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "model = fasttext.load_model(\"jagen_will/preproc/models/lid.176.bin\")\n",
    "paths_train = glob.glob(\"data/songs_text/train/*\")\n",
    "paths_test = glob.glob(\"data/songs_text/test/*\")\n",
    "arg_feats=\"chars\"\n",
    "arg_n=3\n",
    "\n",
    "#myTexts\n",
    "# corpus_clean_select\n",
    "myTexts = tuy.load_texts(paths_train, model, format='txt')\n",
    "# Get features\n",
    "\n",
    "my_feats = fex.get_feature_list(myTexts, feats=arg_feats, n=arg_n, relFreqs=True)\n",
    "mf = 3000\n",
    "if mf < len(my_feats):\n",
    "    val = my_feats[mf][1]\n",
    "    my_feats = [m for m in my_feats if m[1] >= val]\n",
    "\n",
    "with open(\"feature_list.json\", \"w\") as out:\n",
    "    out.write(json.dumps(my_feats))\n",
    "    \n",
    "feat_list = [m[0] for m in my_feats]\n",
    "myTexts = fex.get_counts(myTexts, feat_list=feat_list, feats=arg_feats, n=arg_n, relFreqs=True)\n",
    "\n",
    "unique_texts = [text[\"name\"] for text in myTexts]\n",
    "\n",
    "loc = {}\n",
    "\n",
    "for t in tqdm.tqdm(myTexts):\n",
    "    text, local_freqs = count_process((t, feat_list))\n",
    "    loc[text[\"name\"]] = local_freqs\n",
    "    \n",
    "# Saving metadata for later\n",
    "metadata = pandas.DataFrame(columns=['author', 'lang'], index=unique_texts, data =\n",
    "                                [[t[\"aut\"], t[\"lang\"]] for t in myTexts])\n",
    "# Free some space before doing this...\n",
    "del myTexts\n",
    "\n",
    "feats = pandas.DataFrame.from_dict(loc, columns=list(feat_list), orient=\"index\")\n",
    "pandas.concat([metadata, feats], axis=1).to_csv(\"feats_train.csv\")\n",
    "\n",
    "\n",
    "## And now test\n",
    "myTexts = tuy.load_texts(paths_test, model, format='txt')\n",
    "myTexts = fex.get_counts(myTexts, feat_list=feat_list, feats=arg_feats, n=arg_n, relFreqs=True)\n",
    "unique_texts = [text[\"name\"] for text in myTexts]\n",
    "loc = {}\n",
    "\n",
    "for t in tqdm.tqdm(myTexts):\n",
    "    text, local_freqs = count_process((t, feat_list))\n",
    "    loc[text[\"name\"]] = local_freqs\n",
    "\n",
    "metadata = pandas.DataFrame(columns=['author', 'lang'], index=unique_texts, data =\n",
    "                                [[t[\"aut\"], t[\"lang\"]] for t in myTexts])\n",
    "    \n",
    "del myTexts\n",
    "\n",
    "feats = pandas.DataFrame.from_dict(loc, columns=list(feat_list), orient=\"index\")\n",
    "del loc\n",
    "\n",
    "pandas.concat([metadata, feats], axis=1).to_csv(\"feats_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have created the data, we can run, for instance, a **leave one out** analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... Formatting data ........\n",
      ".......... Creating pipeline according to user choices ........\n",
      ".......... using normalisations ........\n",
      ".......... choosing SVM ........\n",
      ".......... Creating pipeline with steps ........\n",
      "[('scaler', StandardScaler()), ('normalizer', Normalizer()), ('model', LinearSVC())]\n",
      ".......... leave-one-out cross validation will be performed ........\n",
      ".......... using 119 samples ........\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Lennon       0.56      0.57      0.56        60\n",
      "   McCartney       0.55      0.54      0.55        59\n",
      "\n",
      "    accuracy                           0.55       119\n",
      "   macro avg       0.55      0.55      0.55       119\n",
      "weighted avg       0.55      0.55      0.55       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# either run from the command line\n",
    "# python train_svm.py feats_train_n3_k_5000.csv --leave_one_out --norms\n",
    "# OR\n",
    "# the following code bloc\n",
    "import sys \n",
    "import jagen_will.svm\n",
    "import pandas\n",
    "import joblib\n",
    "train = pandas.read_csv(\"feats_train.csv\", index_col=0)\n",
    "test = None\n",
    "\n",
    "svm = jagen_will.svm.train_svm(train, test, leave_one_out=True, norms=True, kernel=\"LinearSVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can go for the final analysis…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... Formatting data ........\n",
      ".......... Creating pipeline according to user choices ........\n",
      ".......... using normalisations ........\n",
      ".......... choosing SVM ........\n",
      ".......... Creating pipeline with steps ........\n",
      "[('scaler', StandardScaler()), ('normalizer', Normalizer()), ('model', LinearSVC())]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Lennon       0.00      0.00      0.00       0.0\n",
      "Lennon-McCartney       0.00      0.00      0.00      60.0\n",
      "       McCartney       0.00      0.00      0.00       0.0\n",
      "\n",
      "        accuracy                           0.00      60.0\n",
      "       macro avg       0.00      0.00      0.00      60.0\n",
      "    weighted avg       0.00      0.00      0.00      60.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbcamps/Data/F/Cours_interventions_colloques/2019-07_DH-Utrecht/wilhelmus/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jbcamps/Data/F/Cours_interventions_colloques/2019-07_DH-Utrecht/wilhelmus/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jbcamps/Data/F/Cours_interventions_colloques/2019-07_DH-Utrecht/wilhelmus/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jbcamps/Data/F/Cours_interventions_colloques/2019-07_DH-Utrecht/wilhelmus/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jbcamps/Data/F/Cours_interventions_colloques/2019-07_DH-Utrecht/wilhelmus/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jbcamps/Data/F/Cours_interventions_colloques/2019-07_DH-Utrecht/wilhelmus/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Same as usual, either run from the command line\n",
    "# python train_svm.py feats_train_n3_k_5000.csv --test_path feats_test_n3_k_5000.csv --norms --final\n",
    "# OR\n",
    "# the following code bloc\n",
    "import jagen_will.svm\n",
    "import pandas\n",
    "import joblib\n",
    "train = pandas.read_csv(\"feats_train.csv\", index_col=0)\n",
    "test = pandas.read_csv(\"feats_test.csv\", index_col=0)\n",
    "\n",
    "svm = jagen_will.svm.train_svm(train, test, norms=True, kernel=\"LinearSVC\", final_pred=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
